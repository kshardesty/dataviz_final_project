---
title: "Data Visualization for Exploratory Data Analysis"
output: 
  html_document:
    keep_md: true
    toc: true
    toc_float: true
---

# Data Visualization Project 03


In this exercise you will explore methods to create different types of data visualizations (such as plotting text data, or exploring the distributions of continuous variables).


## PART 1: Density Plots

Using the dataset obtained from FSU's [Florida Climate Center](https://climatecenter.fsu.edu/climate-data-access-tools/downloadable-data), for a station at Tampa International Airport (TPA) for 2022, attempt to recreate the charts shown below which were generated using data from 2016. You can read the 2022 dataset using the code below: 

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(ggridges)
library(tidytext)
weather_tpa <- read_csv("https://raw.githubusercontent.com/reisanar/datasets/master/tpa_weather_2022.csv")
# random sample 
sample_n(weather_tpa, 4)
```

See https://www.reisanar.com/slides/relationships-models#10 for a reminder on how to use this type of dataset with the `lubridate` package for dates and times (example included in the slides uses data from 2016).

Using the 2022 data: 

(a) Create a plot like the one below:

```{r, echo = FALSE, out.width="80%", fig.align='center'}
knitr::include_graphics("https://github.com/reisanar/figs/raw/master/tpa_max_temps_facet.png")
```

Hint: the option `binwidth = 3` was used with the `geom_histogram()` function.


```{r}
library(lubridate)
tpa_clean <- weather_tpa %>% 
  mutate(month = month(month, label = TRUE, abbr = FALSE),
         day = wday(day, label = TRUE, abbr = FALSE))
```




```{r}
ggplot(tpa_clean, aes(x = max_temp, fill = month)) +
  geom_histogram(binwidth = 3, color = "white", boundary = 2) +
  guides(fill = "none") +
  facet_wrap(vars(month)) +
  theme_bw() +
  labs(x = "Maximum Temperatures", y = "Number of Days")
```


(b) Create a plot like the one below:

```{r, echo = FALSE, out.width="80%", fig.align='center'}
knitr::include_graphics("https://github.com/reisanar/figs/raw/master/tpa_max_temps_density.png")
```

Hint: check the `kernel` parameter of the `geom_density()` function, and use `bw = 0.5`.

```{r}
ggplot(tpa_clean, aes(x = max_temp)) +
  geom_density(color = "grey20", fill = "grey50",
               bw = 0.5, kernel = "epanechnikov")+
  theme_minimal() +
   labs(x = "Maximum temperature")
```


(c) Create a plot like the one below:

```{r, echo = FALSE, out.width="80%", fig.align='center'}
knitr::include_graphics("https://github.com/reisanar/figs/raw/master/tpa_max_temps_density_facet.png")
```

Hint: default options for `geom_density()` were used. 

```{r}
ggplot(tpa_clean, aes(x = max_temp, fill = month)) +
  geom_density() +
  guides(fill = "none") +
  facet_wrap(vars(month)) +
  theme_bw() +
   labs(x = "Maximum temperature", y = "", title = "Density plots for each month in 2022")
```


(d) Generate a plot like the chart below:


```{r, echo = FALSE, out.width="80%", fig.align='center'}
knitr::include_graphics("https://github.com/reisanar/figs/raw/master/tpa_max_temps_ridges_plasma.png")
```

Hint: use the`{ggridges}` package, and the `geom_density_ridges()` function paying close attention to the `quantile_lines` and `quantiles` parameters. The plot above uses the `plasma` option (color scale) for the _viridis_ palette.

```{r}
ggplot(tpa_clean, aes(x = max_temp, y = month, fill = after_stat(x))) +
  geom_density_ridges_gradient(quantile_lines = TRUE, quantiles = 2) +
  scale_fill_viridis_c(option = "plasma", name = "") +
  labs(x = "Maximum temperature (in Fahrenheit degrees)", y = NULL, color = "Temp") +
  theme_minimal()
```



(e) Create a plot of your choice that uses the attribute for precipitation _(values of -99.9 for temperature or -99.99 for precipitation represent missing data)_.

```{r}
ggplot(data=tpa_clean,
      aes(precipitation, month, fill = month)) +
      geom_bar(stat="identity") +
  labs(x = "Precipitation in Inches", y = "Month", title = "Total Precipitation by Month in Tampa for 2022", caption = "Source: FSU Florida Climate Center") +
  theme_minimal() +
  theme(legend.position = "none")
   
  
```


## PART 2 

> **You can choose to work on either Option (A) or Option (B)**. Remove from this template the option you decided not to work on. 


### Option (A): Visualizing Text Data

Review the set of slides (and additional resources linked in it) for visualizing text data: https://www.reisanar.com/slides/text-viz#1

Choose any dataset with text data, and create at least one visualization with it. For example, you can create a frequency count of most used bigrams, a sentiment analysis of the text data, a network visualization of terms commonly used together, and/or a visualization of a topic modeling approach to the problem of identifying words/documents associated to different topics in the text data you decide to use. 

Make sure to include a copy of the dataset in the `data/` folder, and reference your sources if different from the ones listed below:

- [Billboard Top 100 Lyrics](https://github.com/reisanar/datasets/blob/master/BB_top100_2015.csv)

- [RateMyProfessors comments](https://github.com/reisanar/datasets/blob/master/rmp_wit_comments.csv)

- [FL Poly News Articles](https://github.com/reisanar/datasets/blob/master/flpoly_news_SP23.csv)


(to get the "raw" data from any of the links listed above, simply click on the `raw` button of the GitHub page and copy the URL to be able to read it in your computer using the `read_csv()` function)

```{r}
lyrics_2015 <- read_csv("https://raw.githubusercontent.com/reisanar/datasets/master/BB_top100_2015.csv")
lyrics_2015 <- select(lyrics_2015, -Year, -Source)
```

```{r}
lyrics_2015 %>% 
  filter(Rank %in% 1:10)
```

```{r}
lyrics_2015 %>% 
  filter(Rank %in% 1:10) %>% 
  unnest_tokens(word, Lyrics)
```

```{r}
lyrics_2015 %>%
  filter(Rank %in% 1:10) %>%
  unnest_tokens(word, Lyrics, token = "words") %>%
  filter(!word %in% stop_words$word, str_detect(word, "[a-z]"))
```

```{r}
bb_top_10 <- lyrics_2015 %>%
  filter(Rank %in% 1:10) %>%
  unnest_tokens(word, 
                Lyrics, 
                token = "words") %>%
  filter(!word %in% stop_words$word, 
         str_detect(word, "[a-z]"))
```

```{r}
bb_top_10 %>% 
  group_by(word) %>% 
  summarise(uses = n()) %>% 
  arrange(desc(uses)) %>% 
  head(10)
```
```{r}
bb_top_10 %>% 
  group_by(word) %>% 
  summarise(uses = n()) %>% 
  arrange(desc(uses)) %>% 
  slice(1:15) %>% 
  ggplot() + 
  geom_bar(aes(x = word, y = uses, fill = word), 
           stat = "identity") + 
  coord_flip() + 
  scale_x_discrete(breaks=c("youre","yeah","whip", "watch", "uptown", "ooh", "nae", "love", "im", "ill", "girl", "funk", "dont", "bop", "baby"),
        labels=c("You're","Yeah","Whip", "Watch", "Uptown", "Ooh", "Nae", "Love", "I'm", "Ill", "Girl", "Funk", "Don't", "Bop", "Baby")) +
   labs(x = "Word", y = "Number of Uses", title = "Most Used Words in Billboard Top 10 Songs for 2015", subtitle = "(1. Uptown Funk, 2. Thinking Out Loud, 3. See You Again, 4. Trap Queen, 5. Sugar, \n 6. Shut Up and Dance, 7. Blank Space, 8. Watch Me, 9. Earned It, 10. The Hills)", caption = "Source: Billboard Top 100, 2015") +
     theme_minimal() +
  theme(legend.position = "none")
```
```{r}
bb_top_10 %>%
  inner_join(get_sentiments("bing")) %>%
  count(Song, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative)
```

```{r}
bb_top_10 %>%
  inner_join(get_sentiments("bing")) %>%
  count(Song, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative) %>% 
  ggplot() + 
  geom_bar(aes(x = reorder(Song, sentiment), 
               y = sentiment, fill = Song), 
           stat = "identity") + 
  coord_flip() + 
  scale_x_discrete(breaks=c("sugar","uptown funk","thinking out loud", "earned it", "the hills", "shut up and dance", "see you again", "trap queen", "watch me", "blank space"),
        labels=c("Sugar","Uptown Funk","Thinking Out Loud", "Earned It", "The Hills", "Shut Up and Dance", "See You Again", "Trap Queen", "Watch Me", "Blank Space")) +
  labs(x = "", y = "Sentiment", title = "Sentiment Analysis of Billboard Top 10 Songs in 2015", subtitle = "(Using Bing Lexicon)", caption = "Source: Billboard Top 100, 2015") + 
  theme_minimal() +
  theme(legend.position = "none")
```
